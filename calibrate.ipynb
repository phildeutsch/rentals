{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rental_utils' from 'rental_utils.pyc'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import rental_utils; reload(rental_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_json('Data/train.json')\n",
    "test_raw = pd.read_json('Data/test.json')\n",
    "\n",
    "[features, feature_names] = rental_utils.get_features(25, train_raw)\n",
    "\n",
    "train = rental_utils.add_features(train_raw, features, feature_names)\n",
    "test = rental_utils.add_features(test_raw, features, feature_names)\n",
    "\n",
    "train = rental_utils.add_region(train)\n",
    "test = rental_utils.add_region(test)\n",
    "\n",
    "train = rental_utils.add_variables(train, train)\n",
    "test = rental_utils.add_variables(test, train)\n",
    "\n",
    "dv_county = rental_utils.vectorizer('County', train)\n",
    "train = rental_utils.one_hot_encode(dv_county, train, 'County')\n",
    "test = rental_utils.one_hot_encode(dv_county, test, 'County')\n",
    "\n",
    "dv_name = rental_utils.vectorizer('Name', train)\n",
    "train = rental_utils.one_hot_encode(dv_name, train, 'Name')\n",
    "test = rental_utils.one_hot_encode(dv_name, test, 'Name')\n",
    "\n",
    "dv_region = rental_utils.vectorizer('RegionID', train)\n",
    "train = rental_utils.one_hot_encode(dv_region, train, 'RegionID')\n",
    "test = rental_utils.one_hot_encode(dv_region, test, 'RegionID')\n",
    "\n",
    "independent = (['bathrooms', 'bedrooms', 'price'] + feature_names + \n",
    "    ['description_length', 'n_features', 'n_photos', 'month'] +\n",
    "    [x for x in train.columns.values if 'County' in x] +\n",
    "    [x for x in train.columns.values if 'Name' in x] +\n",
    "    [x for x in train.columns.values if 'Region' in x]\n",
    "    )\n",
    "X_train, X_val, y_train, y_val = train_test_split(train[independent], train['interest_level'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 216 out of 216 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing n_estimators value is:     50\n",
      "The best performing max_features value is:     0.33\n",
      "The best performing max_depth value is:        20\n",
      "The best performing min_samples_leaf value is: 5\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 25, 50]\n",
    "max_features = [0.1, 0.2, 0.33, 0.5]\n",
    "max_depth = [10, 20]\n",
    "min_samples_leaf = [1, 2, 5]\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "gridCV = GridSearchCV(RandomForestClassifier(), param_grid=hyperparameters, cv=3, n_jobs=4, verbose=1)\n",
    "\n",
    "gridCV.fit(X_val, y_val)\n",
    "\n",
    "# Identify optimal hyperparameter values\n",
    "best_n_estim      = gridCV.best_params_['n_estimators']\n",
    "best_max_features = gridCV.best_params_['max_features']  \n",
    "best_max_depth = gridCV.best_params_['max_depth']  \n",
    "best_min_samples_leaf = gridCV.best_params_['min_samples_leaf']  \n",
    "\n",
    "print(\"The best performing n_estimators value is:     {}\".format(best_n_estim))\n",
    "print(\"The best performing max_features value is:     {}\".format(best_max_features))\n",
    "print(\"The best performing max_depth value is:        {}\".format(best_max_depth))\n",
    "print(\"The best performing min_samples_leaf value is: {}\".format(best_min_samples_leaf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
