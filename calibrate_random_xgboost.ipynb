{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/rentals/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'rental_utils' from 'rental_utils.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import rental_utils; reload(rental_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_raw = rental_utils.clean(pd.read_json('Data/train.json'))\n",
    "test_raw = rental_utils.clean(pd.read_json('Data/test.json'))\n",
    "\n",
    "[features, feature_names] = rental_utils.get_features(25, train_raw)\n",
    "\n",
    "train = rental_utils.add_features(train_raw, features, feature_names)\n",
    "test = rental_utils.add_features(test_raw, features, feature_names)\n",
    "\n",
    "train = rental_utils.add_region(train)\n",
    "test = rental_utils.add_region(test)\n",
    "\n",
    "train = rental_utils.add_variables(train, train)\n",
    "test = rental_utils.add_variables(test, train)\n",
    "\n",
    "dv_county = rental_utils.vectorizer('County', train)\n",
    "train = rental_utils.one_hot_encode(dv_county, train, 'County')\n",
    "test = rental_utils.one_hot_encode(dv_county, test, 'County')\n",
    "\n",
    "dv_name = rental_utils.vectorizer('Name', train)\n",
    "train = rental_utils.one_hot_encode(dv_name, train, 'Name')\n",
    "test = rental_utils.one_hot_encode(dv_name, test, 'Name')\n",
    "\n",
    "dv_region = rental_utils.vectorizer('RegionID', train)\n",
    "train = rental_utils.one_hot_encode(dv_region, train, 'RegionID')\n",
    "test = rental_utils.one_hot_encode(dv_region, test, 'RegionID')\n",
    "\n",
    "independent = (['bathrooms', 'bedrooms', 'rooms', 'price', 'price_per_room'] + feature_names + \n",
    "    ['description_length', 'n_features', 'n_photos'] +\n",
    "    ['created_year', 'created_month', 'created_weekday', 'created_hour'] +\n",
    "    [x for x in train.columns.values if 'County' in x] +\n",
    "    [x for x in train.columns.values if 'Name' in x] +\n",
    "    [x for x in train.columns.values if 'Region' in x]\n",
    "    )\n",
    "X_train, X_val, y_train, y_val = train_test_split(train[independent], train['interest_level'], test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f158a07af90>, 'learning_rate': [0.05, 0.1, 0.2], 'colsample_bytree': [0.1, 0.2, 0.33, 0.5, 1], 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f158a095110>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "param_dist = {\"learning_rate\": [0.05, 0.1, 0.2],\n",
    "              \"n_estimators\": sp_randint(10,100),\n",
    "              \"max_depth\": sp_randint(6,100),\n",
    "              \"colsample_bytree\": [0.1, 0.2, 0.33, 0.5, 1]\n",
    "             }\n",
    "\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, verbose=1,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing learning_rate value is:    0.1\n",
      "The best performing n_estimators value is:     89\n",
      "The best performing max_depth value is:        73\n",
      "The best performing colsample_bytree value is: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Identify optimal hyperparameter values\n",
    "best_learning_rate     = random_search.best_params_['learning_rate']\n",
    "best_n_estimators = random_search.best_params_['n_estimators']  \n",
    "best_max_depth = random_search.best_params_['max_depth']  \n",
    "best_colsample_bytree = random_search.best_params_['colsample_bytree']  \n",
    "\n",
    "print(\"The best performing learning_rate value is:    {}\".format(best_learning_rate))\n",
    "print(\"The best performing n_estimators value is:     {}\".format(best_n_estimators))\n",
    "print(\"The best performing max_depth value is:        {}\".format(best_max_depth))\n",
    "print(\"The best performing colsample_bytree value is: {}\".format(best_colsample_bytree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss:            0.657\n"
     ]
    }
   ],
   "source": [
    "model = random_search.best_estimator_\n",
    "preds, probs = rental_utils.predict(model, X_val)\n",
    "print('Log loss:            ' + str(round(log_loss(y_val, probs), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"Models/best_xgb.pkl\", \"wb\"))\n",
    "model2 = pickle.load(open(\"Models/best_xgb.pkl\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
